{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Probability & Statistics: I\n",
    "\n",
    "*Davide Gerosa (Milano-Bicocca)*\n",
    "\n",
    "##### Reading:\n",
    "\n",
    "- [Ivezic textbook](https://press.princeton.edu/books/hardcover/9780691198309/statistics-data-mining-and-machine-learning-in-astronomy) Chapter 3. \n",
    "- [David Hogg: \"Data analysis recipes: Probability calculus for inference\"](https://arxiv.org/abs/1205.4446)\n",
    "\n",
    "\n",
    "This course is based on previous work by many people. See [here]((https://github.com/dgerosa/astrostatistics_bicocca_2022/blob/main/README.md) for credits.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preliminaries and notation <a class=\"anchor\" id=\"one\"></a>\n",
    "\n",
    "* **\"Statistics\"** = extracting knowledge from data.\n",
    "* **\"Astrostatistics\"** = extracting knowledge from astronomical data.\n",
    "* **\"Knowledge\"** = summary (physical or phenomenological) of data behavior.\n",
    "* **\"Data\"** = result of measurements.\n",
    "\n",
    "In the textbook, $x$ is a scalar quantity that is measured $N$ times to form a dataset.\n",
    "\n",
    "* $x_i$ is a single measurement with $i=1,...,N$.\n",
    "* $\\{x_i\\}$ refers to the set of all N measurements comprising the dataset. \n",
    "\n",
    "Our data can be real numbers, discrete labels (strings or numbers), or even \"missing values\" (we sometimes pad our datasets with NaNs in this case). \n",
    "\n",
    "**Goal of data mining & statistical inference:**\n",
    "> We are generally trying to *estimate* $h(x)$, the *true* generating distribution from which $\\{x_i\\}$ are drawn. \n",
    "\n",
    "* $h(x)$ is the **probability density (distribution) function** or the **\"pdf\"** and $h(x)dx$ is the propobability of a value lying between $x$ and $x+dx$. This distribution can have several levels-- the population distribution of events (e.g. source redshifts), and a measurement uncertainity distribution that blurs our measured data away from true values.\n",
    "\n",
    "* The \"left to right\" integral of $h(x)$ is the **cumulative distribution function** (**\"cdf\"**), $H(x) = \\int_{-\\infty}^x h(x')dx'$. The inverse function of the cdf is the **quantile function**, e.g. what $x$ value has 90% of the distribution below it?\n",
    "\n",
    "* While $h(x)$ is the \"true\" pdf (or **population** pdf).  What we *measure* from the data is the **empirical** pdf, which is denoted $f(x)$.  So, $f(x)$ is a *model* of $h(x)$.  In principle, with infinite data $f(x) \\rightarrow h(x)$, but in reality the blurring effect of measurement errors keep this from being strictly true. Likewise, the empirical cdf is denoted $F(x)$.\n",
    "\n",
    "* If we are attempting to guess a physical *model* for $h(x)$, then the process is ***parametric***.  With a model solution we can generate new data that should mimic what we measure.  If we are not attempting to guess a model, then the process is ***non-parametric***, i.e. we are just trying to describe the data behavior in a compact practical way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on uncertainties and errors\n",
    "\n",
    "* Technically, errors are systematic biases that we can not mitigate through collecting lots and lots of data. \n",
    "* Statistical uncertainties are the result of random measurement uncertainty. \n",
    "* But \"error\" will be used for both, and denoted as either statistical errors (error bars) or systematic errors (biases).\n",
    "\n",
    "\n",
    "* Statistical error distributions (error bars) that vary from data point to data point are called **heteroscedastic errors**. If they are the same for all points then they are **homoscedastic errors**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  We could summarize the goal of this course as an attempt to \n",
    "\n",
    "1) estimate $f(x)$ from some real (possibly multi-dimensional) data set, \n",
    "\n",
    "2) find a way to describe $f(x)$ and its uncertainty, \n",
    "\n",
    "3) compare it to models of $h(x)$, and then \n",
    "\n",
    "4) use the knowledge that we have gained to interpret/predict new measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probability <a class=\"anchor\" id=\"two\"></a>\n",
    "\n",
    "> $p(A)$ = the probability of $A$ (or the probability density at $A$; I'm sloppy!) \n",
    "\n",
    "e.g. the probability that an observed object is a galaxy. This does not mean that the object is in some sort of Schrodinger's cat quantum uncertainity...*the probability reflects our current state of knowledge of the object, and our belief that it is a galaxy*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Probability axioms (Kolmogorov)\n",
    "\n",
    "1. $p(A)\\geq0 \\quad\\forall\\, A$\n",
    "2. $p(\\Omega) = 1$, where $\\Omega$ is the set of all outcomes, i.e. the sum/integral of all possible outcomes is unity\n",
    "3. $p(\\cup_{i=1}^\\infty A_i) = \\sum_{i=1}^\\infty p(A_i)$ if all events are independent\n",
    "\n",
    "$A \\cup B$ is the *union* of sets $A$ and $B$. **Read as A OR B.**\n",
    "\n",
    "$A \\cap B$ is the *intersection* of sets $A$ and $B$. **Read as A AND B.** Different notations $p(A \\cap B) = p(AB) = p(A,B) = p(A\\,\\mathrm{and}\\,B)$. We will use the comma notation throughout. \n",
    "\n",
    "If we have two events, $A$ and $B$, the possible combinations are illustrated by the following figure:\n",
    "![Figure 3.1](http://www.astroml.org/_images/fig_prob_sum_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The probability that ***either*** $A$ ***or*** $B$ will happen (which could include both) is the *union*, given by\n",
    "$$p(A \\cup B) = p(A) + p(B) - p(A \\cap B)$$\n",
    "The figure makes it clear why the last term is necessary.  Since $A$ and $B$ overlap, we are double-counting the region where *both* $A$ and $B$ happen, so we have to subtract this out.  \n",
    "\n",
    "\n",
    "* The probability that ***both*** $A$ ***and*** $B$ will happen, $p(A \\cap B)$, is \n",
    "$$p(A \\cap B) = p(A|B)p(B) = p(B|A)p(A)$$\n",
    "where p(A|B) is the probability of A *given that* B is true and is called the **conditional probability**.  So the $|$ is short for \"given\".\n",
    "\n",
    "\n",
    "* The **law of total probability** says that (for independent $B_i$)\n",
    "$$p(A) = \\sum_ip(A|B_i)p(B_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is important to realize that the following is *always* true:\n",
    "\n",
    "$$p(A,B) = p(A|B)p(B) = p(B|A)p(A)$$\n",
    "\n",
    "However, if $A$ and $B$ are independent, then $p(A|B)=p(A)$ and $p(B|A)=p(B)$ and\n",
    "\n",
    "$$p(A,B) = p(A)p(B)$$\n",
    "\n",
    "**EXAMPLE** (classic marbles in bag scenario)\n",
    "\n",
    "If you have a bag with 5 marbles (3 yellow and 2 blue) and you want to know the probability of picking 2 yellow marbles in a row, that would be\n",
    "\n",
    "$$p(Y_1,Y_2) = p(Y_1)p(Y_2|Y_1).$$\n",
    "\n",
    "$p(Y_1) = \\frac{3}{5}$ since you have an equally likely chance of drawing any of the 5 marbles.\n",
    "\n",
    "If you did not put the first marble back in the back after drawing it (sampling *without* \"replacement\"), then the probability\n",
    "\n",
    "$p(Y_2|Y_1) = \\frac{2}{4}$, so that\n",
    "\n",
    "$$p(Y_1,Y_2) = \\frac{3}{5}\\frac{2}{4} = \\frac{3}{10}.$$\n",
    "\n",
    "But if you put the first marble back, then\n",
    "\n",
    "$p(Y_2|Y_1) = \\frac{3}{5} = p(Y_2)$, so that \n",
    "\n",
    "$$p(Y_1,Y_2) = \\frac{3}{5}\\frac{3}{5} = \\frac{9}{25}.$$\n",
    "\n",
    "In the first case $A$ and $B$ (or rather $Y_1$ and $Y_2$) are *not* independent, whereas in the second case they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes' Theorem <a class=\"anchor\" id=\"three\"></a>\n",
    "\n",
    "In the following figure, we have a 2-D distribution in $x-y$ parameter space.  Here $x$ and $y$ are ***not*** independent as, once you pick a $y$, your values of $x$ are constrained.\n",
    "\n",
    "![http://www.astroml.org/_images/fig_conditional_probability_1.png](http://www.astroml.org/_images/fig_conditional_probability_1.png)\n",
    "\n",
    "We have that \n",
    "$$p(x,y) = p(x|y)p(y) = p(y|x)p(x)$$\n",
    "\n",
    "We can define the ***marginal probability*** as\n",
    "$$p(x) = \\int p(x,y)dy,$$\n",
    "\n",
    "where marginal means projecting on to one axis (integrating over the unwanted variable). The **marginal** distributions are shown on the left and bottom sides of the left panel.  As the equation above says, this is just the integral along the $x$ direction for a given $y$ (left side panel) or the integral along the $y$ direction for a given $x$ (bottom panel).  \n",
    "\n",
    "The three panels on the right show the ***conditional probability*** (of $x$) for three $y$ values: $$p(x|y=y_0)$$  These are just normalized \"slices\" through the 2-D distribution.\n",
    "\n",
    "The marginal probability of $x$ can be re-written as\n",
    "\n",
    "$$p(x) = \\int p(x|y)p(y) dy$$\n",
    "\n",
    "But since $p(x|y)p(y) = p(y|x)p(x)$, we can write\n",
    "\n",
    "> $$p(y|x) = \\frac{p(x|y)p(y)}{p(x)} = \\frac{p(x|y)p(y)}{\\int p(x|y)p(y) dy}$$\n",
    "\n",
    "which in words says that\n",
    "\n",
    "> the (conditional) probability of $y$ given $x$ is just the (conditional) probability of $x$ given $y$ times the (marginal) probability of $y$ divided by the (marginal) probability of $x$, where the latter is just the integral of the numerator.\n",
    "\n",
    "This is **Bayes' Theorem**, which itself is not at all controversial, though its application can be as we'll discuss later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes' Theorem Example: Monty Hall Problem (or \"Deal Or No Deal\") <a class=\"anchor\" id=\"five\"></a>\n",
    "\n",
    "A very famous stats mind trick.. You might have seen this already.\n",
    "\n",
    "The [Monty Hall Problem](https://en.wikipedia.org/wiki/Monty_Hall_problem) was originally posed (and solved) in a letter by Steve Selvin to the American Statistician in [1975](https://www.tandfonline.com/doi/abs/10.1080/00031305.1975.10479121). It became famous as a question from reader Craig F. Whitaker's letter quoted in Marilyn vos Savant's \"Ask Marilyn\" column in Parade magazine in 1990\n",
    "\n",
    "\n",
    "You are playing a TV game show and are shown 2 doors.  One has a car behind it, the other a goat.  What are your chances of picking the door with the car?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "OK, now there are 3 doors: one with a car, two with goats.  The game show host asks you to pick a door, but not to open it yet.  Then the host opens one of the other two doors (that you did not pick) and that has a goat.  The host offers you the opportunity to switch doors.\n",
    "\n",
    "- One player decides to switch\n",
    "- Another player prefers to stay with the previous choice\n",
    " \n",
    "![https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Monty_open_door.svg/180px-Monty_open_door.svg.png](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Monty_open_door.svg/180px-Monty_open_door.svg.png)\n",
    "\n",
    "- Now a third player comes in who has not seen what happened earlier. They pick a door.\n",
    "\n",
    "*Which of the three players is most likely to win?*\n",
    "\n",
    "You might know or remember the answer already... but don't think now! **Let's simulate it**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to get you hands dirty! Open a jupyter notebook and code it up! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Simulate three doors, one car, and two goats.\n",
    " - Simulate three players: the switcher, the conservative, and the newcomer. \n",
    " - Record who wins.\n",
    " - Repeat it many times.\n",
    " - Which player do you want to be?\n",
    " \n",
    " - What would happen if you had 100 doors to choose from and the presenter opens 98 or them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes' Theorem Example: Contingency Table  and COVID Tests\n",
    "\n",
    "We can also use Bayes' rule to learn something about false positives and false negatives.\n",
    "\n",
    "Let's look at COVID tests.  The test can be positive ($T=1$) or negative ($T=0$) and one can either have the disease ($D=1$) or not ($D=0$).  So, there are 4 possible combinations:\n",
    "$$T=0; D=0 \\;\\;\\;  {\\rm true \\; negative}$$\n",
    "$$T=0; D=1 \\;\\;\\; {\\rm false \\; negative}$$\n",
    "$$T=1; D=0 \\;\\;\\; {\\rm false \\; positive}$$\n",
    "$$T=1; D=1 \\;\\;\\; {\\rm true \\; positive}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "All else being equal, you have a 50% chance of being misdiagnosed.  Not good!  But the probability of disease and the accuracy of the test presumably are not random.\n",
    "\n",
    "If the rates of false positive and false negative are:\n",
    "$$p(T=1|D=0) = \\epsilon_{\\rm FP}$$\n",
    "$$p(T=0|D=1) = \\epsilon_{\\rm FN}$$\n",
    "\n",
    "then the true positive and true negative rates are just:\n",
    "$$p(T=0| D=0) = 1-\\epsilon_{\\rm FP}$$\n",
    "$$p(T=1| D=1) = 1-\\epsilon_{\\rm FN}$$\n",
    "\n",
    "Let's assume that $\\epsilon_{\\rm FP}=0.02$ and $\\epsilon_{\\rm FN}=0.001$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In graphical form this $p(T|D)$ matrix is:\n",
    "![http://www.astroml.org/_images/fig_contingency_table_1.png](http://www.astroml.org/_images/fig_contingency_table_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we have a **prior** regarding how likely the disease is, we can take this into account.\n",
    "\n",
    "$$p(D=1)=\\epsilon_D$$\n",
    "\n",
    "and then $p(D=0)=1-\\epsilon_D$. Say, $\\epsilon_D$ = 0.01. \n",
    "\n",
    "Now assume that a person tested positive. What is the probability that this person has the disease? Is it 98% \n",
    "because $\\epsilon_{\\rm FP}=0.02$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We can't just read $p(D=1|T=1)$ off the table because the table entry is the conditional probability of the *test* given the *disease*, $p(T=1|D=1)$. What we want is the conditional probability of the *disease* given the *test*, that is, $p(D=1|T=1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bayes' Theorem then can be used to help us determine how likely it is that you have the disease if you tested positive:\n",
    "\n",
    "$$p(D=1|T=1) = \\frac{p(T=1|D=1)p(D=1)}{p(T=1)},$$\n",
    "\n",
    "where $$p(T=1) = p(T=1|D=0)p(D=0) + p(T=1|D=1)p(D=1).$$\n",
    "\n",
    "So\n",
    "$$p(D=1|T=1) = \\frac{(1 - \\epsilon_{FN})\\epsilon_D}{\\epsilon_{FP}(1-\\epsilon_D) + (1-\\epsilon_{FN})\\epsilon_D} \\approx \\frac{\\epsilon_D}{\\epsilon_{FP}+\\epsilon_D}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "where in the final approximation we assume that all $\\epsilon$ values are small. That means that to get a reliable diagnosis, we need $\\epsilon_{FP}$ to be quite small.  (Because you *want* the probability to be close to unity if you test positive, otherwise it is a *false* positive).\n",
    "\n",
    "In our example, we have a disease rate of 1% ($\\epsilon_D = 0.01$) and a false positive rate of 2% ($\\epsilon_{\\rm FP}=0.02$).  \n",
    "\n",
    "So we have\n",
    "$$p(D=1|T=1) = \\frac{0.01}{0.02+0.01} = 0.333$$\n",
    "\n",
    "Then in a sample of, e.g.,  1000 people, 10 people will *actually* have the disease $(1000*0.01)$, but another 20 $(1000*0.02)$ will test positive! \n",
    "\n",
    "Therefore, in that sample of 30 people who tested positive, only 1/3 has the disease\n",
    "(not 98%!). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations of random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $x$ is a random variable then $f(x)$ is also a random variable for any function $f$.\n",
    "\n",
    "To transform probability distributions when taking functions of random variables, we can simply use conservation of dimensionless probability, i.e. \n",
    "\n",
    "$$\\mathrm{Prob}(x, x+dx) = \\mathrm{Prob}(y, y+dy)$$\n",
    "\n",
    "$$p(x)dx = p(y)dy.$$ \n",
    "\n",
    "where $y = f(x)$.\n",
    "\n",
    "Thus, $$p(y) = \\left|\\frac{dx}{dy}\\right| p(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXAMPLE**\n",
    "\n",
    "* Let $x$ be a random variable drawn from a uniform distribution between $0$ and $1$. So $p(x) = 1/(1-0) = 1$.  \n",
    "* Let's transform to $y = e^x$.\n",
    "* So $p(y) = \\left|dy/dx\\right|^{-1}p(x) = 1/y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![https://www.astroml.org/_images/fig_transform_distribution_1.png](https://www.astroml.org/_images/fig_transform_distribution_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to get you hands dirty!\n",
    "\n",
    "### Pdf of the log\n",
    "1. Use `numpy` to draw $N$ (where $N$ is large...) random samples from a uniform distribution between $0.1$ and $10$, and store these samples as $x$.\n",
    "2. Use matplotlib to make a histogram of these samples.\n",
    "3. Compute the base-10 log of your array $x$, and store this as $y$.\n",
    "4. Make another histogram for $y$. Using the equation to transform probability distributions, write what the theoretical pdf of $y$ is, and overplot it onto your histogram.\n",
    "5. Compute the log of the mean of $x$ and the mean of $y$. Now compute the log of the median of $x$ and the median of $y$. \n",
    "\n",
    "You should note that the means are different, but the medians (as it is a cumulative statistic) are the same. The mean is affected by the scale of the sample values, but the median only depends on the ordering of the samples. Monotonic transformations (like taking the log) do not change the ordering of samples.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "sky"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
