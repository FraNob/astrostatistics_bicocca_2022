{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 18: Supernovae with GPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's fit our supernova synthetic data from last time using GPR.\n",
    "\n",
    "- The key ingrediente in getting a good GPR fit is the choice of the kernel and its parameters.\n",
    "- Check out what's available in the `kernels` submodule of [sklearn.gaussian_process](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.gaussian_process)\n",
    "- *Hint*. Radial-basis function kernel (aka squared-exponential kernel) is a standard choice in the GPR world.\n",
    "- Plot the expectation value of the fit as well as the resulting 1-$\\sigma$ and 2-$\\sigma$ contours.\n",
    "- Interpret the results.\n",
    "\n",
    "*Note*. We have time constraints, so feel free to tweak the hyperparameters manually while in class. But, of course, a publication-quality result will require a cross-validation analysis. (Do this at home before the exam?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a suite of *data-driven predictive models* for our supernova dataset. That is: we can faithfully predict how a future redshift/distance measurement will look like given the current sample.\n",
    "\n",
    "This is already great and these kind of tools are immensely useful in a variety of contexts (also involving a lot of money: suppose you want to predict how much a give financial asset will perform on tomorrow's stock market... You  might not really care about expressing the underlying financial model in simple terms, as long as your investments are profitable).\n",
    "\n",
    "For the case of supernovae, however, we have do have physical theory which is $\\Lambda$CDM.\n",
    "\n",
    "- First, refresh your cosmology and write down the predicted relationship between the distance module $\\mu$ and the redshift $\\sigma$. *Hint* I always forget these things, my to-go reference is [Hogg (2010)](https://arxiv.org/abs/astro-ph/9905116). I got:\n",
    "\n",
    "$$\\mu = 5 \\log \\left( \\frac{c/H_0} {10 {\\rm pc}}(1+z)\\int_0^z \\frac{dz'}{\\sqrt{\\Omega_m (1+z^3)+\\Omega_\\Lambda}} \\right) $$\n",
    "\n",
    "\n",
    "- Assuming a flat Universe,  we have a parametric non-linear model for $\\mu(z)$ that depends on two parameters, the Hubble constant $H_0$ and the matter content of the Universe $\\Omega_m$\n",
    "- It's a very non-linear model. Fir it to the data (however you want to do it).\n",
    "- What are the measured value of $H_0$ and $\\Omega_m$. Are they correlated?\n",
    "- How would a model without dark energy (i.e. $\\Omega_m=1$) perform? Do these data contain evidence of dark energy?\n",
    "\n",
    "The European Space Agency is considering new cosmology-related space mission. They ask you to figure out what science you can do with 10 times more measurement compared to what you have right now. That is: you want to clone your data. We've seen this earlier in the class, but now we can do much better.\n",
    "- Assume a uniform distribution in redshifts between 0 and z.\n",
    "- Using both the GPR fit and your latest $\\Lambda$CDM fit, generate a set of $\\mu$ measurements that respects the statistical properties of the data you were given. \n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
